<!DOCTYPE html>
<html class="h-100" lang="en">
 <head>
  <meta content="width=device-width,initial-scale=1" name="viewport"/>
  <meta content="authenticity_token" name="csrf-param">
   <meta content="URtjMFGGk4Vxr_i1i57hNMME7evC1GUCUWpnGmhdzpNCjbocMYphQ5X1huT1XjSqhxdmGlXVjQ3Z_JApg0RPKA" name="csrf-token"/>
   <meta name="csp-nonce"/>
   <title>
    Chapter 35. GPU Program Optimization | NVIDIA Developer
   </title>
   <meta content="NVIDIA Developer" property="og:site_name"/>
   <meta content="Chapter 35. GPU Program Optimization" property="og:title"/>
   <meta content="website" property="og:type"/>
   <meta content="https://developer.download.nvidia.com/images/og-default.jpg" property="og:image"/>
   <meta content="https://developer.nvidia.com/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-35-gpu-program-optimization" property="og:url"/>
   <meta content="Chapter 35. GPU Program Optimization" name="twitter:title"/>
   <meta content="https://developer.download.nvidia.com/images/og-default.jpg" name="twitter:image"/>
   <meta content="@NVIDIA" name="twitter:site"/>
   <meta content="summary_large_image" name="twitter:card"/>
   <meta content="@NVIDIA" name="twitter:creator"/>
   <link href="https://dirms4qsy6412.cloudfront.net/assets/application-cda6c2ad01dd5384edde86239b14e09ac6e33dd34e35caaa34e61e1313f84752.css" media="all" rel="stylesheet"/>
   <link href="https://dirms4qsy6412.cloudfront.net/assets/highlight-7c6157fe69da4cc401cddeb387737d6991b2012dc14e90f3d52764a3a58fd3da.css" rel="stylesheet"/>
   <link href="https://dirms4qsy6412.cloudfront.net/assets/one-trust-bea625cf16a072ce5fdb0707a19f2645daf63c05eb1a016db72773eba008fc07.css" rel="stylesheet"/>
   <script charset="UTF-8" data-document-language="true" data-domain-script="3e2b62ff-7ae7-4ac5-87c8-d5949ecafff5" src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js">
   </script>
   <script src="https://images.nvidia.com/aem-dam/Solutions/ot-js/ot-custom.js">
   </script>
   <script>
    function OptanonWrapper() {
    let event = new Event('bannerLoaded');
    window.dispatchEvent(event);

    if (window.OnetrustActiveGroups && window.OnetrustActiveGroups.includes("C0002")) {
      window.DD_RUM && window.DD_RUM.init({
        clientToken: 'pub0430c74fae5d2b467bcb8d48b13e5b32',
        applicationId: '9fc963c7-14e6-403d-bdec-ee671550bb7f',
        site: 'datadoghq.com',
        service: 'devzone',
        env: 'production',
        version: '',
        sessionSampleRate: 10,
        sessionReplaySampleRate: 5,
        trackUserInteractions: true,
        trackResources: true,
        trackLongTasks: true,
        defaultPrivacyLevel: 'mask-user-input',
      });
    }
  }
   </script>
   <script>
    (function() {
    var didInit = false;
    function initMunchkin() {
      if(didInit === false) {
        didInit = true;
        Munchkin.init('156-OFN-742');
      }
    }
    var s = document.createElement('script');
    s.type = 'text/javascript';
    s.async = true;
    s.src = '//munchkin.marketo.net/munchkin.js';
    s.onreadystatechange = function() {
      if (this.readyState == 'complete' || this.readyState == 'loaded') {
        initMunchkin();
      }
    };
    s.onload = initMunchkin;
    document.getElementsByTagName('head')[0].appendChild(s);
})();
   </script>
   <link href="https://dirms4qsy6412.cloudfront.net/assets/gpu_gems-a881bfce95294488891610c871683bdc3a6792c1c85df1bbe502a32d4a9e4d2c.css" media="all" rel="stylesheet"/>
   <script data-ot-ignore="true" src="https://assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js">
   </script>
   <script crossorigin="anonymous" integrity="sha512-STof4xm1wgkfm7heWqFJVn58Hm3EtS31XFaagaa8VMReCXAkQnJZ+jEy8PCC/iT18dFy95WcExNHFTqLyp72eQ==" referrerpolicy="no-referrer" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.3/jquery.min.js">
   </script>
   <script src="https://dirms4qsy6412.cloudfront.net/assets/bootstrap/5.1.3/bootstrap.bundle.min-51ad1d8cab4ebd9873a0429f5e67ca717a71fd96daf8025bc04a88848e5b375c.js">
   </script>
   <link href="https://dirms4qsy6412.cloudfront.net/assets/favicon-81bff16cada05fcff11e5711f7e6212bdc2e0a32ee57cd640a8cf66c87a6cbe6.ico" rel="icon" type="image/x-icon"/>
  </meta>
 </head>
 <body class="d-flex flex-column h-100">
  <div id="header">
  </div>
  <div class="container page gpugems_page">
   <div class="row">
    <div class="col-md-8">
     <div id="book_switch">
      <a class="btn-cta" href="/gpugems/gpugems">
       GPUGems
      </a>
      <a class="btn-cta" href="/gpugems/gpugems2">
       GPUGems2
      </a>
      <a class="btn-cta" href="/gpugems/gpugems3">
       GPUGems3
      </a>
     </div>
     <div id="book_header">
      <a href="https://developer.nvidia.com/gpugems2">
       <img alt="GPU Gems 2" src="https://dirms4qsy6412.cloudfront.net/assets/gpu_gems/gpugems/GPU_Gems_2-3cb7dd1f4b339e2a615c8d04edbc4f9557c6ed1129b5ba81bd7a5af51854c9a0.jpg"/>
      </a>
      <h2 class="h--huge">
       <a href="https://developer.nvidia.com/gpugems2">
        GPU Gems 2
       </a>
      </h2>
      DebugTranslate:
GPU Gems 2 is now available, right here, online. You can purchase a beautifully printed version of this book, and others in the series, at a 30% discount courtesy of InformIT and Addison-Wesley.
      DebugTranslate:
    The CD content, including demos and content, is available on the web and for download.
     </div>
     <h1 class="docChapterTitle" data-parent="Part IV: General-Purpose Computation on GPUS: A Primer">
      DebugTranslate:Chapter 35. GPU
        Program Optimization
     </h1>
     DebugTranslate:Cliff Woolley
University of Virginia
     DebugTranslate:As GPU programmability has become more pervasive and GPU performance has become almost irresistibly appealing,
        increasing numbers of programmers have begun to recast applications of all sorts to make use of GPUs. But an
        interesting trend has appeared along the way: it seems that many programmers make the same performance mistakes
        in their GPU programs regardless of how much experience they have programming CPUs. The goal of this chapter is
        to help CPU programmers who are new to GPU programming avoid some of these common mistakes so that they gain the
        benefits of GPU performance without all the headaches of the GPU programmer's learning curve.
     <h2>
      DebugTranslate:35.1 Data-Parallel Computing
     </h2>
     DebugTranslate:One of the biggest hurdles you'll face when first programming a GPU is learning how to get the most out of a
        data-parallel computing environment. This parallelism exists at several levels on the GPU, as described in
        Chapter 29 of this book, "Streaming Architectures and Technology Trends." First, parallel execution on multiple
        data elements is a key design feature of modern GPUs. Vertex and fragment processors operate on four-vectors,
        performing four-component instructions such as additions, multiplications, multiply-accumulates, or dot products
        in a single cycle. They can schedule more than one of these instructions per cycle per pipeline. This provides
        ample opportunities for the extraction of instruction-level parallelism within a GPU program. For example, a
        series of sequential but independent scalar multiplications might be combined into a single four-component
        vector multiplication. Furthermore, parallelism can often be extracted by rearranging the data itself. For
        example, operations on a large array of scalar data will be inherently scalar. Packing the data in such a way
        that multiple identical scalar operations can occur simultaneously provides another means of exploiting the
        inherent parallelism of the GPU. (See Chapter 44 of this book, "A GPU Framework for Solving Systems of Linear
        Equations," for examples of this idea in practice.)
     <h4>
      DebugTranslate:35.1.1 Instruction-Level Parallelism
     </h4>
     DebugTranslate:While modern CPUs do have SIMD processing extensions such as MMX or SSE, most CPU programmers never attempt to
        use these capabilities themselves. Some count on the compiler to make use of SIMD extensions when possible; some
        ignore the extensions entirely. As a result, it's not uncommon to see new GPU programmers writing code that
        ineffectively utilizes vector arithmetic.
     DebugTranslate:Let's take an example from a real-world application written by a first-time GPU programmer. In the following
        code snippet, we have a texture coordinate center and a uniform value called params. From
        them, a new coordinate offset is computed that will be used to look up values from the texture
        Operator:
     <pre><code class="language-cpp">float2 offset = float2(params.x * center.x - 0.5f * (params.x - 1.0f),
                       params.x *center.y - 0.5f * (params.x - 1.0f));
float4 O = f4texRECT(Operator, offset);</code></pre>
     DebugTranslate:While the second line of this snippet (the actual texture lookup) is already as concise as possible, the first
        line leaves a lot to be desired. Each multiplication, addition, or subtraction is operating on a scalar value
        instead of a four-vector, wasting computational resources. Compilers for GPU programs are constantly getting
        better at detecting situations like this, but it's best to express arithmetic operations in vector form up front
        whenever possible. This helps the compiler do its job, and more important, it helps the programmer get into the
        habit of thinking in terms of vector arithmetic.
     DebugTranslate:The importance of that habit becomes clearer when we look at the next snippet of code from that same fragment
        program. Here we take the center texture coordinate and use it to compute the coordinates of the four
        texels adjacent to center.
     <pre><code class="language-cpp">float4 neighbor =
    float4(center.x - 1.0f, center.x + 1.0f, center.y - 1.0f, center.y + 1.0f);
float output = (-O.x * f1texRECT(Source, float2(neighbor.x, center.y)) +
                -O.x * f1texRECT(Source, float2(neighbor.y, center.y)) +
                -O.y * f1texRECT(Source, float2(center.x, neighbor.z)) +
                -O.z * f1texRECT(Source, float2(center.x, neighbor.w))) /
               O.w;</code></pre>
     DebugTranslate:Now not only have we made the mistake of expressing our additions and subtractions in scalar form, but we've
        also constructed from the four separate scalar results a four-vector neighbor that isn't even exactly
        what we need. To get the four texture coordinates we actually want, we have to assemble them one by
        one. That requires a number of move instructions. It would have been better to let the four-vector addition
        operation assemble the texture coordinates for us. The swizzle operator, discussed later in Section
        35.2.4, helps here by letting us creatively rearrange the four-vector produced by the addition into multiple
        two-vector texture coordinates.
     DebugTranslate:Performing the necessary manipulations to improve vectorization, here is an improved version of the preceding
        program:
     <pre><code class="language-cpp">float2 offset = center.xy - 0.5f;
offset = offset * params.xx + 0.5f; // multiply-and-accumulate
float4 x_neighbor = center.xyxy + float4(-1.0f, 0.0f, 1.0f, 0.0f);
float4 y_neighbor = center.xyxy + float4(0.0f, -1.0f, 0.0f, 1.0f);
float4 O = f4texRECT(Operator, offset);
float output = (-O.x * f1texRECT(Source, x_neighbor.xy) +
                -O.x * f1texRECT(Source, x_neighbor.zw) +
                -O.y * f1texRECT(Source, y_neighbor.xy) +
                -O.z * f1texRECT(Source, y_neighbor.zw)) /
               O.w;</code></pre>
     DebugTranslate:An additional point of interest here is that the expression offset * params.xx + 0.5f, a
        multiply-and-accumulate operation, can be expressed as a single GPU assembly instruction and thus can execute in
        a single cycle. This allows us to achieve twice as many floating-point operations in the same amount of time.
     DebugTranslate:Finally, notice that the output value could have been computed using a four-vector dot product.
        Unfortunately, while one of the two input vectors, O, is already on hand, the second one must be
        assembled from the results of four separate scalar texture lookups. Fortunately, the multiply-and-accumulate
        operation comes to the rescue once again in this instance. But in general, it seems wasteful to assemble
        four-vectors from scalar values just to get the benefit of a single vector operation. That's where data-level
        parallelism comes into play.
     <h4>
      DebugTranslate:35.1.2 Data-Level Parallelism
     </h4>
     DebugTranslate:Some problems are inherently scalar in nature and can be more effectively parallelized by operating on multiple
        data elements simultaneously. This data-level parallelism is particularly common in GPGPU applications, where
        textures and render targets are used to store large 2D arrays of scalar source data and output values. Packing
        the data more efficiently in such instances exposes the data-level parallelism. Of course, determining which
        packing of the data will be the most efficient requires a bit of creativity and is application-specific. Two
        common approaches are as follows:
     <ul>
      <li>
       DebugTranslate:Split the data grid up into quadrants and stack the quadrants on top of each other by packing corresponding
          scalar values into a single RGBA texel, as shown in Figure 35-1.
       <br/>
       <div align="center" class="figure">
        <img alt="35_gpuforcpu_01.jpg" src="https://developer.download.nvidia.com/books/gpugems2/35_gpuforcpu_01.jpg"/>
        DebugTranslate:Figure 35-1 Packing Data by Stacking Grid Quadrants
       </div>
      </li>
      <li>
       DebugTranslate:Take each group of four adjacent texels and pack them down into a single RGBA texel, as shown in Figure
          35-2.
       <br/>
       <div align="center" class="figure">
        <img alt="35_gpuforcpu_02.jpg" src="https://developer.download.nvidia.com/books/gpugems2/35_gpuforcpu_02.jpg"/>
        DebugTranslate:Figure 35-2 Packing Data by Stacking Adjacent Texels
       </div>
      </li>
     </ul>
     DebugTranslate:There are ups and downs to each of these approaches, of course. While in theory there is a 4x speedup to be had
        by quartering the total number of fragments processed, the additional overhead of packing the data is
        significant in some cases, especially if the application requires the data to be unpacked again at the end of
        processing.
     DebugTranslate:In some cases, application-specific data arrangements can be used to provide the speed of vector processing
        without the packing or unpacking overhead. For example, Goodnight et al. (2003a) use a data layout tailored to
        their application, which accelerates arbitrary-size separable convolutions on the GPU. Their approach trades off
        space for computation time by replicating the scalar data four times into the four channels for an RGBA texture,
        shifting the data by one texel in a given dimension per channel, as shown in Figure 35-3. Although this does not
        have the advantage of decreasing the number of fragments processed, it still leverages data-level parallelism by
        arranging data that will be used together in such a way that it can be accessed more efficiently, providing an
        overall speedup.
     <div align="center" class="figure">
      <img alt="35_gpuforcpu_03.jpg" src="https://developer.download.nvidia.com/books/gpugems2/35_gpuforcpu_03.jpg"/>
      DebugTranslate:Figure 35-3 Custom Data Packing for Separable Convolutions
     </div>
     <h2>
      DebugTranslate:35.2 Computational Frequency
     </h2>
     DebugTranslate:The next step in learning how to program GPUs effectively is learning to exploit the fact that the GPU
        comprises several different processors. Consider the typical rasterization pipeline. As implemented in hardware,
        the pipeline consists of a sequence of processors that operate in parallel and have different capabilities,
        degrees of programmability, strengths, and weaknesses. Between each stage of the pipeline is a work queue.
        Unless a pipeline stage's output work queue is full, that stage can work in parallel with other stages. While
        the CPU is busy handing off geometry and state information to the GPU, the GPU's vertex processor can process
        each vertex that arrives, transforming it and so forth. Simultaneously, the rasterizer can convert groups of
        transformed vertices into fragments (potentially many fragments), queuing them up for processing by the fragment
        processor.
     DebugTranslate:Notice that the relative amount of work at each stage of the pipeline is typically increasing: a few vertices
        can result in the generation of many fragments, each of which can be expensive to process. Given this relative
        increase in the amount of work done at each stage, it is helpful to view the stages conceptually as a series of
        nested loops (even though each loop operates in parallel with the others, as just described). These conceptual
        nested loops work as shown in pseudocode in Listing 35-1.
     <h4>
      DebugTranslate:Example 35-1. The Standard Rasterization Pipeline as a Series of Nested Loops
     </h4>
     <pre><code class="language-cpp">foreach
  tri in triangles
  {
    // run the vertex program on each vertex
    v1 = process_vertex(tri.vertex1);
    v2 = process_vertex(tri.vertex2);
    v3 = process_vertex(tri.vertex2);
    // assemble the vertices into a triangle
    assembledtriangle = setup_tri(v1, v2, v3);
    // rasterize the assembled triangle into [0..many] fragments
    fragments = rasterize(assembledtriangle);
    // run the fragment program on each fragment
    foreach
      frag in fragments { outbuffer[frag.position] = process_fragment(frag); }
  }</code></pre>
     DebugTranslate:For each operation we perform, we must be mindful of how computationally expensive that operation is and how
        frequently it is performed. In a normal CPU program, this is fairly straightforward. With an actual series of
        nested loops (as opposed to the merely conceptual nested loops seen here), it's easy to see that a given
        expression inside an inner loop is loop-invariant and can be hoisted out to an outer loop and computed less
        frequently. Inner-loop branching in CPU programs is often avoided for similar reasons; the branch is expensive,
        and if it occurs in the inner loop, then it occurs frequently.
     DebugTranslate:When writing GPU programs, it is particularly crucial to minimize the amount of redundant work. Naturally, all
        of the same techniques discussed previously for reducing computational frequency in CPU programs apply to GPU
        programs as well. But given the nature of GPU programming, each of the conceptual nested loops in Listing 35-1
        is actually a separate program running on different hardware and possibly even written in different
        programming languages. That separation makes it easy to overlook some of these sorts of optimizations.
     <h4>
      DebugTranslate:35.2.1 Precomputation of Loop Invariants
     </h4>
     DebugTranslate:The first mistake a new GPU programmer is likely to make is to needlessly recompute values that vary linearly
        or are uniform across the geometric primitives inside a fragment program. Texture coordinates are a prime
        example. They vary linearly across the primitive being drawn, and the rasterizer interpolates them
        automatically. But when multiple related texture coordinates are used (such as the offset and
        neighbor coordinates in the example in Section 35.1.1), a common mistake is to compute the related
        values in the fragment program. This results in a possibly expensive computation being performed very
        frequently.
     DebugTranslate:It would be much better to move the computation of the related texture coordinates into the vertex program.
        Though this effectively just shifts load around and interpolation in the rasterizer is still a per-fragment
        operation, the question is how much work is being done at each stage of the pipeline and how
        often that work must be done. Either way we do it, the result will be a set of texture coordinates that
        vary linearly across the primitive being drawn. But interpolation is often a lot less computationally expensive
        than recomputation of a given value on a per-fragment basis. As long as there are many more fragments than
        vertices, shifting the bulk of the computation so that it occurs on a per-vertex rather than a per-fragment
        basis makes sense.
     DebugTranslate:It is worth reemphasizing, however, that any value that varies linearly across the domain can be
        computed in this way, regardless of whether it will eventually be used to index into a texture. Herein lies one
        of the keys to understanding GPU programming: the names that "special-purpose" GPU features go by are mostly
        irrelevant as long as you understand how they correspond to general-purpose concepts. Take a look at Chapter 31
        of this book, "Mapping Computational Concepts to GPUs," for an in-depth look at those correspondences.
     DebugTranslate:To take the concept of hoisting loop-invariant code a step further, some values are best precomputed on the CPU
        rather than on the GPU. Any value that is constant across the geometry being drawn can be factored all the way
        out to the CPU and passed to the GPU program as a uniform parameter. This sometimes results in parameters that
        are less than semantically elegant; for example, suppose we pass a uniform parameter size to a vertex
        or fragment program, but the program only uses the value size * size * 100. Although size and
        even size squared have semantic meaning, size squared times 100 has little. But again, if the
        GPU programs are equated to a series of nested loops and the goal is to remove redundant loop-invariant
        computations, it is likely still preferable to compute size * size * 100 on the CPU and pass that as
        the uniform parameter value to the GPU.
     <h4>
      DebugTranslate:35.2.2 Precomputation Using Lookup Tables
     </h4>
     DebugTranslate:In the more classic sense, "precomputation" means computation that is done offline in advance—the classic
        storage versus computation trade-off. This concept also maps readily onto GPUs: functions with a constant-size
        domain and range that are constant across runs of an algorithm—even if they vary in complex ways based on their
        input—can be precomputed and stored in texture maps.
     DebugTranslate:Texture maps can be used for storing functions of one, two, or three variables over a finite domain as 1D, 2D,
        or 3D textures. Textures are usually indexed by floating-point texture coordinates between 0 and 1. The range is
        determined by the texture format used; 8-bit texture formats can only store values in the range [0, 1], but
        floating-point textures provide a much larger range of possible values. Textures can store up to four channels,
        so you can encode as many as four separate functions in the same texture. Texture lookups also provide filtering
        (interpolation), which you can use to get piecewise linear approximations to values in between the table
        entries.
     DebugTranslate:As an example, suppose we had a fragment program that we wanted to apply to a checkerboard: half of the
        fragments of a big quad, the "red" ones, would be processed in one pass, while the other half, the "black"
        fragments, would be processed in a second pass. But how would the fragment program determine whether the
        fragment it was currently processing was red or black? One way would be to use modulo arithmetic on the
        fragment's position:
     <pre><code class="language-cpp">// Calculate red-black (odd-even) masks
float2 intpart;
float2 place = floor(1.0f - modf(round(position + 0.5f) / 2.0f, intpart));
float2 mask = float2((1.0f - place.x) * (1.0f - place.y), place.x *place.y);
if (((mask.x + mask.y) &amp;&amp; do_red) || (!(mask.x + mask.y) &amp;&amp; !do_red))
{
  // ...
}</code></pre>
     DebugTranslate:Here, roughly speaking, place is the location of the fragment modulo 2 and mask.x and
        mask.y are Boolean values that together tell us whether the fragment is red or black. The uniform
        parameter do_red is set to 0 if we want to process the black fragments and 1 if we want the red
        fragments.
     DebugTranslate:But clearly this is all a ridiculous amount of work for a seemingly simple task. It's much easier to precompute
        a checkerboard texture that stores a 0 in black texels and a 1 in red texels. Then we can skip all of the
        preceding arithmetic, replacing it with a single texture lookup, providing a substantial speedup. What we're
        left with is the following:
     <pre><code class="language-cpp">half4 mask = f4texRECT(RedBlack, IN.redblack);
/*
*
mask.x and mask.w tell whether IN.position.x and IN.position.y
*
are both odd or both even, respectively. Either of these two
*
conditions indicates that the fragment is red. params.x==1
*
selects red; params.y==1 selects black.
*/
if (dot(mask, params.xyyx))
{
  ...
}</code></pre>
     DebugTranslate:However, although table lookups in this case were a win in terms of performance, that's not always going to be
        the case. Many GPU applications—particularly those that use a large number of four-component floating-point
        texture lookups—are memory-bandwidth-limited, so the introduction of an additional texture read in order to save
        a small amount of computation might in fact be a loss rather than a win. Furthermore, texture cache coherence is
        critical; a lookup table that is accessed incoherently will thrash the cache and hurt performance rather than
        help it. But if enough computation can be "pre-baked" or if the GPU programs in question are compute-limited
        already, and if the baked results are read from the texture in a spatially coherent way, table lookups can
        improve performance substantially. See Section 35.3 later in this chapter for more on benchmarking and GPU
        application profiling.
     <h4>
      DebugTranslate:35.2.3 Avoid Inner-Loop Branching
     </h4>
     DebugTranslate:In CPU programming, it is often desirable to avoid branching inside inner loops. This usually involves making
        several copies of the loop, with each copy acting on a subset of the data and following the execution path
        specific to that subset. This technique is sometimes called static branch resolution or
        substreaming.
     DebugTranslate:The same concept applies to GPUs. Because a fragment program conceptually represents an inner loop, applying
        this technique requires a fragment program containing a branch to be divided into multiple fragment programs
        without the branch. The resulting programs each account for one code execution path through the original,
        monolithic program. This technique also requires the application to subdivide the data, which for the GPU means
        rasterization of multiple primitives instead of one. See Chapter 34 of this book, "GPU Flow-Control Idioms," for
        details.
     DebugTranslate:A typical example is a 2D grid where data elements on the boundary of the grid require special handling that
        does not apply to interior elements. In this case, it is preferable to create two separate fragment programs—a
        short one that does not account for boundary conditions and a longer one that does—and draw a filled-in quad
        over the interior elements and an outline quad over the boundary elements.
     <h4>
      DebugTranslate:35.2.4 The Swizzle Operator
     </h4>
     DebugTranslate:An easily overlooked or underutilized feature of GPU programming is the swizzle operator. Because all
        registers on the GPU are four-vectors but not all instructions take four-vectors as arguments, some mechanism
        for creating other-sized vectors out of these four-vector registers is necessary. The swizzle operator provides
        this functionality. It is syntactically similar to the C concept of a structure member access but has the
        additional interesting property that data members can be rearranged, duplicated, or omitted in arbitrary
        combinations, as shown in the following example:
     <pre><code class="language-cpp">float4 f = float4(1.0f, 2.0f, 3.0f, 4.0f);
float4 g = float4(5.0f, 6.0f, 7.0f, 8.0f);
float4 h = float4(0.1f, 0.2f, 0.3f, 0.4f);
// note that h.w is syntactically equivalent to h.wwww
float4 out = f.xyyz * g.wyxz + h.w; // this is one instruction!
                                    // multiply-and-accumulate again.
// result: out is (8.4f, 12.4f, 10.4f, 21.4f)</code></pre>
     DebugTranslate:The swizzle operator has applications in the computational frequency realm. For example, consider the common
        case of a fragment program that reads from three adjacent texels: (x, y), (x - 1,
        y), and (x + 1, y). Computing the second and third texture coordinates from the first
        is a job best left to the vertex program and rasterizer, as has already been discussed. But the rasterizer can
        interpolate four-vectors as easily as it can two-vectors, so there is no reason that these three texture
        coordinates should have to occupy three separate interpolants. In fact, there are only four distinct values
        being used: x, x - 1, x + 1, and y. So all three texture coordinates can
        actually be packed into and interpolated as a single four-vector. The three distinct two-vector texture
        coordinates are simply extracted (for free) from the single four-vector interpolant in the fragment program by
        using swizzle operators, as shown here:
     <pre><code class="language-cpp">struct vertdata
{
  float4 position : POSITION;
  float4 texcoord : TEXCOORD0;
} vertdata vertexprog(vertdata IN)
{
  vertdata OUT;
  OUT.position = IN.position;
  OUT.texcoord = float4(IN.texcoord.x, IN.texcoord.y, IN.texcoord.x - 1,
                        IN.texcoord.x + 1);
  return vertdata;
}
frag2frame fragmentprog(vertdata IN, uniform samplerRECT texmap)
{
  ... float4 center = f4texRECT(texmap, IN.texcoord.xy);
  float4 left = f4texRECT(texmap, IN.texcoord.zy);
  float4 right = f4texRECT(texmap, IN.texcoord.wy);
  ...
}</code></pre>
     DebugTranslate:Not only does this save on arithmetic in the vertex processor, but it saves interpolants as well. Further, it
        avoids the construction of vectors in the fragment program: swizzles are free (on NVIDIA GeForce FX and GeForce
        6 Series GPUs), but the move instructions required to construct vectors one channel at a time are not. We saw
        this same issue in Section 35.1.1.
     DebugTranslate:Also worth mentioning is a syntactic cousin of the swizzle operator: the write mask operator. The
        write mask specifies a subset of the destination variable's components that should be modified by the current
        instruction. This can be used as a hint to the compiler that unnecessary work can be avoided. For example, if a
        write mask is applied to a texture lookup, memory bandwidth could be saved because texture data in channels that
        will never be used need not be read from texture memory. Note that although the syntax of a write mask is
        similar to that of a swizzle, the concepts of rearranging or duplicating channels do not apply to a write mask.
     <pre><code class="language-cpp">float4 out;
out = float4(1.0f, 2.0f, 3.0f, 4.0f);
out.xz = float4(5.0f, 6.0f, 7.0f, 8.0f);
// result: out is (5.0f, 2.0f, 7.0f, 4.0f)</code></pre>
     <h2>
      DebugTranslate:35.3 Profiling and Load Balancing
     </h2>
     DebugTranslate:As with CPU programming, the best way to write efficient GPU code is to write something straightforward that
        works and then optimize it iteratively as necessary. Unfortunately, this process currently isn't quite as easy
        with GPU code, because fewer tools exist to help with it. But a bit of extra diligence on the part of the
        programmer allows optimization to be done effectively even in the absence of special tools.
     DebugTranslate:Frequent timing measurements are the key. In fact, every optimization that gets applied should be
        independently verified by timing it. Even optimizations that seem obvious and certain to result in a
        speedup can in fact provide no gain at all or, worse, cause a slowdown. When this happens, it might indicate a
        load imbalance in the graphics pipeline, but such problems can also arise because the final optimization step
        occurs inside the graphics driver, making it difficult for the programmer to know exactly what code is really
        being executed. A transformation made on the source code that seems beneficial might in fact disable some other
        optimization being done by the driver, causing a net loss in performance. These sorts of problems are much more
        easily detected by benchmarking after each optimization; backtracking to isolate problematic optimizations after
        the fact is a waste of time and energy.
     DebugTranslate:Once the obvious optimizations have been applied, a low-level understanding of the capabilities of the
        hardware, particularly in terms of superscalar instruction issues, becomes useful. The more detailed your
        knowledge of what kinds of instructions can be executed simultaneously, the more likely you will be to recognize
        additional opportunities for code transformation and improvement. The NVShaderPerf tool helps with this by
        showing you exactly how your fragment programs schedule onto the arithmetic units of the GPU, taking much of the
        guesswork out of fragment program optimization. (For more information on NVShaderPerf, see "References" at the
        end of the chapter.)
     DebugTranslate:Even with the most highly tuned fragment programs imaginable, there's still a chance that a GPU
        application can be made to run faster. At this point it becomes a matter of finding the main bottleneck in the
        application and shifting load away from it as much as possible. The first step is to use a CPU-application
        profiling tool, such as Rational Quantify, Intel VTune, or AMD CodeAnalyst. This can help pinpoint problems like
        driver overhead (such as in context switching). Not all of the information that such a profiler
        provides will be reliable; many graphics API calls are nonblocking so that the CPU and GPU can operate in
        parallel. At some point, the GPU's work queue will fill up and an arbitrary API call on the CPU side will block
        to wait for the GPU to catch up. The blocked call will be counted by the CPU profiler as having taken a long
        time to execute, even if the work done during that time would be more fairly attributed to an earlier API call
        that did not block. As long as this caveat is kept in mind, however, CPU profilers can still provide valuable
        insights.
     DebugTranslate:Once CPU overhead is minimized, the only remaining issue is determining where the GPU bottlenecks lie.
        Specialized tools for monitoring GPU performance are beginning to appear on the market for this purpose;
        NVPerfHUD is a good example (see "References" for more on NVPerfHUD). To the extent that these tools do not yet
        provide detailed information or are inapplicable to a particular application (NVPerfHUD, for example, is
        currently Direct3D-only and is not well suited to GPGPU applications), other techniques can be utilized to fill
        in the gaps. Each involves a series of experiments. One approach is to test whether the addition of work to a
        given part of the GPU pipeline increases the total execution time or the reduction of work decreases execution
        time. If so, it's likely that that is where the main bottleneck lies. For example, if a fragment program is
        compute-limited, then inserting additional computation instructions will increase the time it takes the program
        to execute; but if the program is memory-bandwidth-limited, the extra computation can probably be done for free.
        An alternate approach is to underclock either the compute core or the memory system of the graphics card. If the
        memory system can be underclocked without decreasing performance, then memory bandwidth is not the limiting
        factor. These techniques and many more are detailed in the NVIDIA GPU Programming Guide (NVIDIA 2004).
     DebugTranslate:Ultimately, understanding the bottlenecks is the key to knowing how to get them to go away. A
        combination of the preceding techniques and a bit of experience will aid in that understanding.
     <h2>
      DebugTranslate:35.4 Conclusion
     </h2>
     DebugTranslate:As we've seen, GPU program optimization shares many common themes with CPU program optimization. High-level
        languages for GPGPU that provide a unified stream programming model (and thus, hopefully, more opportunities for
        global GPU application optimization) are emerging (McCool et al. 2002, Buck et al. 2004), and automatic
        optimization of GPU code is constantly improving. But until those technologies have matured, GPU programmers
        will continue to have to take responsibility for high-level optimizations and understand the details of the
        hardware they're working with to get the most out of low-level optimizations. Hopefully this chapter has given
        you the tools you need to learn how best to extract from your GPU application all of the performance that the
        GPU has to offer.
     <h2>
      DebugTranslate:35.5 References
     </h2>
     DebugTranslate:Buck, Ian, Tim Foley, Daniel Horn, Jeremy Sugerman, Kayvon
        Fatahalian, Mike Houston, and Pat Hanrahan. 2004. "Brook for GPUs: Stream Computing on Graphics Hardware."
        ACM Transactions on Graphics (Proceedings of SIGGRAPH 2004) 23(3), pp. 777–786. Available online at
        http://graphics.stanford.edu/projects/brookgpu/
     DebugTranslate:Goodnight, Nolan, Rui Wang, Cliff Woolley, and Greg Humphreys.
        2003a. "Interactive Time-Dependent Tone Mapping Using Programmable Graphics Hardware." In
        Eurographics Symposium on Rendering: 14th Eurographics Workshop on Rendering, pp. 26–37.
     DebugTranslate:Goodnight, Nolan, Cliff Woolley, Gregory Lewin, David Luebke, and
        Greg Humphreys. 2003b. "A Multigrid Solver for Boundary Value Problems Using Programmable Graphics Hardware." In
        Proceedings of the SIGGRAPH/Eurographics Workshop on Graphics Hardware 2003, pp. 102–111.
     DebugTranslate:McCool, Michael D., Zheng Qin, and Tiberiu S. Popa. 2002. "Shader
        Metaprogramming." In Proceedings of the SIGGRAPH/Eurographics Workshop on Graphics Hardware 2002, pp.
        57–68. Revised article available online at
        http://www.cgl.uwaterloo.ca/Projects/rendering/Papers/index.html#metaprog
     DebugTranslate:NVIDIA. 2004. NVIDIA GPU Programming Guide. Available
        online at
        http://developer.nvidia.com/object/gpu_programming_guide.html
     DebugTranslate:NVPerfHUD. Available online at
        http://developer.nvidia.com/object/nvperfhud_home.html
     DebugTranslate:NVShaderPerf. Available online at
        http://developer.nvidia.com/object/nvshaderperf_home.html
     <!-- generated html end -->
     <!-- Copyright info for The Cg Tutorial -->
     <hr/>
     <h4>
      DebugTranslate:Copyright
     </h4>
     DebugTranslate:Many of the designations used by manufacturers and sellers to distinguish their products are claimed as
        trademarks. Where those designations appear in this book, and Addison-Wesley was aware of a trademark claim, the
        designations have been printed with initial capital letters or in all capitals.
     DebugTranslate:The authors and publisher have taken care in the preparation of this book, but make no expressed or implied
        warranty of any kind and assume no responsibility for errors or omissions. No liability is assumed for
        incidental or consequential damages in connection with or arising out of the use of the information or programs
        contained herein.
     DebugTranslate:NVIDIA makes no warranty or representation that the techniques described herein are free from any Intellectual
        Property claims. The reader assumes all risk of any such claims based on his or her use of these techniques.
     DebugTranslate:The publisher offers excellent discounts on this book when ordered in quantity for bulk purchases or special
        sales, which may include electronic versions and/or custom covers and content particular to your business,
        training goals, marketing focus, and branding interests. For more information, please contact:
     DebugTranslate: U.S. Corporate and Government Sales
        (800) 382-3419
corpsales@pearsontechgroup.com
     DebugTranslate:For sales outside of the U.S., please contact:
     DebugTranslate: International Sales
international@pearsoned.com
     DebugTranslate:Visit Addison-Wesley on the Web: www.awprofessional.com
     DebugTranslate:Library of Congress Cataloging-in-Publication Data
     DebugTranslate:GPU gems 2 : programming techniques for high-performance graphics and general-purpose
        computation / edited by Matt Pharr ; Randima Fernando, series editor.
        p. cm.
        Includes bibliographical references and index.
        ISBN 0-321-33559-7 (hardcover : alk. paper)
        1. Computer graphics. 2. Real-time programming. I. Pharr, Matt. II. Fernando, Randima.

        T385.G688 2005
        006.66—dc22
        2004030181
     DebugTranslate:GeForce™ and NVIDIA Quadro® are trademarks or registered trademarks of NVIDIA Corporation.
     DebugTranslate:Nalu, Timbury, and Clear Sailing images © 2004 NVIDIA Corporation.
     DebugTranslate:mental images and mental ray are trademarks or registered trademarks of mental images, GmbH.
     DebugTranslate:Copyright © 2005 by NVIDIA Corporation.
     DebugTranslate:All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or
        transmitted, in any form, or by any means, electronic, mechanical, photocopying, recording, or otherwise,
        without the prior consent of the publisher. Printed in the United States of America. Published simultaneously in
        Canada.
     DebugTranslate:For information on obtaining permission for use of material from this work, please submit a written request
        to:
     DebugTranslate: Pearson Education, Inc.
        Rights and Contracts Department
        One Lake Street
        Upper Saddle River, NJ 07458
     DebugTranslate:Text printed in the United States on recycled paper at Quebecor World Taunton in Taunton, Massachusetts.
     DebugTranslate:Second printing, April 2005
     <h2>
      DebugTranslate:Dedication
     </h2>
     <blockquote>
      DebugTranslate:To everyone striving to make today's best computer graphics look primitive tomorrow
     </blockquote>
     <!-- <div align="right" style=" color:#999999;">Last Update: 09:24 09/22/2008</div> -->
    </div>
    <div class="col-md-4">
     <ul class="nv-list">
      <li class="">
       <a href="/gpugems/gpugems2/copyright">
        Copyright
       </a>
      </li>
      <li class="">
       <a href="/gpugems/gpugems2/inside-back-cover">
        Inside Back Cover
       </a>
      </li>
      <li class="">
       <a href="/gpugems/gpugems2/inside-front-cover">
        Inside Front Cover
       </a>
      </li>
      <li class="">
       <a href="/gpugems/gpugems2/part-i-geometric-complexity">
        Part I: Geometric Complexity
       </a>
      </li>
      <li>
       <ul>
        <li class="">
         <a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-1-toward-photorealism-virtual-botany">
          Chapter 1. Toward Photorealism in Virtual Botany
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-2-terrain-rendering-using-gpu-based-geometry">
          Chapter 2. Terrain Rendering Using GPU-Based Geometry Clipmaps
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-3-inside-geometry-instancing">
          Chapter 3. Inside Geometry Instancing
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-4-segment-buffering">
          Chapter 4. Segment Buffering
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-5-optimizing-resource-management-multistreaming">
          Chapter 5. Optimizing Resource Management with Multistreaming
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-6-hardware-occlusion-queries-made-useful">
          Chapter 6. Hardware Occlusion Queries Made Useful
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-7-adaptive-tessellation-subdivision-surfaces">
          Chapter 7. Adaptive Tessellation of Subdivision Surfaces with Displacement Mapping
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-i-geometric-complexity/chapter-8-pixel-displacement-mapping-distance-functions">
          Chapter 8. Per-Pixel Displacement Mapping with Distance Functions
         </a>
        </li>
       </ul>
      </li>
      <li class="">
       <a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows">
        Part II: Shading, Lighting, and Shadows
       </a>
      </li>
      <li>
       <ul>
        <li class="">
         <a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-9-deferred-shading-stalker">
          Chapter 9. Deferred Shading in S.T.A.L.K.E.R.
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-10-real-time-computation-dynamic">
          Chapter 10. Real-Time Computation of Dynamic Irradiance Environment Maps
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-11-approximate-bidirectional-texture">
          Chapter 11. Approximate Bidirectional Texture Functions
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-12-tile-based-texture-mapping">
          Chapter 12. Tile-Based Texture Mapping
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-13-implementing-mental-images">
          Chapter 13. Implementing the mental images Phenomena Renderer on the GPU
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-14-dynamic-ambient-occlusion-and">
          Chapter 14. Dynamic Ambient Occlusion and Indirect Lighting
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-15-blueprint-rendering-and-sketchy">
          Chapter 15. Blueprint Rendering and "Sketchy Drawings"
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-16-accurate-atmospheric-scattering">
          Chapter 16. Accurate Atmospheric Scattering
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-17-efficient-soft-edged-shadows-using">
          Chapter 17. Efficient Soft-Edged Shadows Using Pixel Shader Branching
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-18-using-vertex-texture-displacement">
          Chapter 18. Using Vertex Texture Displacement for Realistic Water Rendering
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-ii-shading-lighting-and-shadows/chapter-19-generic-refraction-simulation">
          Chapter 19. Generic Refraction Simulation
         </a>
        </li>
       </ul>
      </li>
      <li class="">
       <a href="/gpugems/gpugems2/part-iii-high-quality-rendering">
        Part III: High-Quality Rendering
       </a>
      </li>
      <li>
       <ul>
        <li class="">
         <a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-20-fast-third-order-texture-filtering">
          Chapter 20. Fast Third-Order Texture Filtering
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-21-high-quality-antialiased-rasterization">
          Chapter 21. High-Quality Antialiased Rasterization
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-22-fast-prefiltered-lines">
          Chapter 22. Fast Prefiltered Lines
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-23-hair-animation-and-rendering-nalu-demo">
          Chapter 23. Hair Animation and Rendering in the Nalu Demo
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-24-using-lookup-tables-accelerate-color">
          Chapter 24. Using Lookup Tables to Accelerate Color Transformations
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-25-gpu-image-processing-apples-motion">
          Chapter 25. GPU Image Processing in Apple's Motion
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-26-implementing-improved-perlin-noise">
          Chapter 26. Implementing Improved Perlin Noise
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-27-advanced-high-quality-filtering">
          Chapter 27. Advanced High-Quality Filtering
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-iii-high-quality-rendering/chapter-28-mipmap-level-measurement">
          Chapter 28. Mipmap-Level Measurement
         </a>
        </li>
       </ul>
      </li>
      <li class="">
       <a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer">
        Part IV: General-Purpose Computation on GPUS: A Primer
       </a>
      </li>
      <li>
       <ul>
        <li class="">
         <a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-29-streaming-architectures">
          Chapter 29. Streaming Architectures and Technology Trends
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-30-geforce-6-series-gpu">
          Chapter 30. The GeForce 6 Series GPU Architecture
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-31-mapping-computational">
          Chapter 31. Mapping Computational Concepts to GPUs
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-32-taking-plunge-gpu">
          Chapter 32. Taking the Plunge into GPU Computing
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-33-implementing-efficient">
          Chapter 33. Implementing Efficient Parallel Data Structures on GPUs
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-34-gpu-flow-control-idioms">
          Chapter 34. GPU Flow-Control Idioms
         </a>
        </li>
        <li class="active">
         <a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-35-gpu-program-optimization">
          Chapter 35. GPU Program Optimization
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-36-stream-reduction">
          Chapter 36. Stream Reduction Operations for GPGPU Applications
         </a>
        </li>
       </ul>
      </li>
      <li class="">
       <a href="/gpugems/gpugems2/part-v-image-oriented-computing">
        Part V: Image-Oriented Computing
       </a>
      </li>
      <li>
       <ul>
        <li class="">
         <a href="/gpugems/gpugems2/part-v-image-oriented-computing/chapter-37-octree-textures-gpu">
          Chapter 37. Octree Textures on the GPU
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-v-image-oriented-computing/chapter-38-high-quality-global-illumination">
          Chapter 38. High-Quality Global Illumination Rendering Using Rasterization
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-v-image-oriented-computing/chapter-39-global-illumination-using-progressive">
          Chapter 39. Global Illumination Using Progressive Refinement Radiosity
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-v-image-oriented-computing/chapter-40-computer-vision-gpu">
          Chapter 40. Computer Vision on the GPU
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-v-image-oriented-computing/chapter-41-deferred-filtering-rendering-difficult">
          Chapter 41. Deferred Filtering: Rendering from Difficult Data Formats
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-v-image-oriented-computing/chapter-42-conservative-rasterization">
          Chapter 42. Conservative Rasterization
         </a>
        </li>
       </ul>
      </li>
      <li class="">
       <a href="/gpugems/gpugems2/part-vi-simulation-and-numerical-algorithms">
        Part VI: Simulation and Numerical Algorithms
       </a>
      </li>
      <li>
       <ul>
        <li class="">
         <a href="/gpugems/gpugems2/part-vi-simulation-and-numerical-algorithms/chapter-43-gpu-computing-protein">
          Chapter 43. GPU Computing for Protein Structure Prediction
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-vi-simulation-and-numerical-algorithms/chapter-44-gpu-framework-solving">
          Chapter 44. A GPU Framework for Solving Systems of Linear Equations
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-vi-simulation-and-numerical-algorithms/chapter-45-options-pricing-gpu">
          Chapter 45. Options Pricing on the GPU
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-vi-simulation-and-numerical-algorithms/chapter-46-improved-gpu-sorting">
          Chapter 46. Improved GPU Sorting
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-vi-simulation-and-numerical-algorithms/chapter-47-flow-simulation-complex">
          Chapter 47. Flow Simulation with Complex Boundaries
         </a>
        </li>
        <li class="">
         <a href="/gpugems/gpugems2/part-vi-simulation-and-numerical-algorithms/chapter-48-medical-image-reconstruction">
          Chapter 48. Medical Image Reconstruction with the FFT
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </div>
   </div>
  </div>
  <div class="mt-auto" id="footer">
  </div>
  <script src="https://dirms4qsy6412.cloudfront.net/assets/nv-developer-menu-d8d15ccc07c1868747c0d32b7e8c7f2876f21dd411c1f3444f182707b2af3fba.js">
  </script>
  <script>
   let menuLocale = 'en';

  if (menuLocale == 'en') {
    menuLocale = 'en-US';
  }

  function mountHeader(data = false) {
    let options = {
      baseURL: window.location.origin,
      signedIn: false,
      locale: menuLocale
    };

    if (data) {
      options.secondaryMenu = data;
    }


      options.showMembershipCardLink = true;

    new NVDeveloperHeader({
      target: document.getElementById('header'),
      props: options
    });
  }

  function mountFooter(data = false) {
    let options = {
      menu: data,
      locale: menuLocale
    };

    new NVDeveloperFooter({
      target: document.getElementById('footer'),
      props: options
    });
  }

  let url = 'd29g4g2dyqv443.cloudfront.net';
  let headerMenuURL = "https://d29g4g2dyqv443.cloudfront.net/menu/en-US/header-secondary.json";

  fetch(headerMenuURL)
    .then(response => response.json())
    .then(data => {
      mountHeader(data);
    })
    .catch((error) => {
      mountHeader();
      window.nv.tracing.addError('menu', error);
    });

  fetch(`https://${url}/menu/${menuLocale}/footer.json`)
    .then(response => response.json())
    .then(data => {
      mountFooter(data);
    })
    .catch((error) => {
      mountFooter();
      window.nv.tracing.addError('menu', error);
    });
  </script>
  <script src="https://www.datadoghq-browser-agent.com/us1/v5/datadog-rum.js">
  </script>
  <script>
   let silentAuthHost = 'www.nvidia.com';
  let crossOriginPageUrl = `https://${silentAuthHost}/auth/hints/`;

  function readHint() {
    return new Promise((resolve) => {
      const { origin: targetOrigin } = new URL(crossOriginPageUrl);

      const iframe = document.createElement('iframe');
      iframe.hidden = true;
      iframe.src = crossOriginPageUrl;

      function responseHandler(event) {
        if (event.origin === targetOrigin) {
          iframe.parentNode.removeChild(iframe);
          return resolve(event.data);
        }
      }

      window.addEventListener('message', responseHandler, { once: true });

      iframe.onload = () => {
        iframe.contentWindow.postMessage({ type: 'read' }, targetOrigin);
      }

      document.body.appendChild(iframe);
    });
  }

  function writeHint(login_hint, idp_id, timestamp, sub) {
    const { origin: targetOrigin } = new URL(crossOriginPageUrl);

    const iframe = document.createElement('iframe');
    iframe.hidden = true;
    iframe.src = crossOriginPageUrl;

    iframe.onload = () => {
      const message = { type: 'write', login_hint, idp_id, timestamp, sub };
      iframe.contentWindow.postMessage(message, targetOrigin);
    }

    document.body.appendChild(iframe);
  }

  function deleteHint() {
    const { origin: targetOrigin } = new URL(crossOriginPageUrl);

    const iframe = document.createElement('iframe');
    iframe.hidden = true;
    iframe.src = crossOriginPageUrl;

    iframe.onload = () => {
      iframe.contentWindow.postMessage({ type: 'delete' }, targetOrigin);
    }

    document.body.appendChild(iframe);
  }
  </script>
  <script>
   _satellite.pageBottom();
  </script>
  <script src="https://api-prod.nvidia.com/search/nvidia-gallery-widget.js">
  </script>
  <script src="https://dirms4qsy6412.cloudfront.net/assets/nv-gallery-widget-3773782f8ce6c8c8a941c2b9081c011da255a54832177fb8bd2e6c7967d37182.js">
  </script>
  <script defer="defer" src="https://dirms4qsy6412.cloudfront.net/packs/js/runtime-503119e3bfeec75056bc.js">
  </script>
  <script defer="defer" src="https://dirms4qsy6412.cloudfront.net/packs/js/692-70104789368a40f2d231.js">
  </script>
  <script defer="defer" src="https://dirms4qsy6412.cloudfront.net/packs/js/647-2379c90e9e5d3379c823.js">
  </script>
  <script defer="defer" src="https://dirms4qsy6412.cloudfront.net/packs/js/97-aa2def7eab63b4c6da8c.js">
  </script>
  <script defer="defer" src="https://dirms4qsy6412.cloudfront.net/packs/js/839-cc0cb35777843d83581f.js">
  </script>
  <script defer="defer" src="https://dirms4qsy6412.cloudfront.net/packs/js/311-033b6299b51897e65419.js">
  </script>
  <script defer="defer" src="https://dirms4qsy6412.cloudfront.net/packs/js/252-f83b27d9f72fef366bc7.js">
  </script>
  <script defer="defer" src="https://dirms4qsy6412.cloudfront.net/packs/js/823-a9c897a627c9bc4bacbd.js">
  </script>
  <script defer="defer" src="https://dirms4qsy6412.cloudfront.net/packs/js/126-1905521c8c79644452ee.js">
  </script>
  <script defer="defer" src="https://dirms4qsy6412.cloudfront.net/packs/js/900-5abf49765bf40a2e9e97.js">
  </script>
  <script defer="defer" src="https://dirms4qsy6412.cloudfront.net/packs/js/application-e3a16d9ab660b995e775.js">
  </script>
  <script defer="defer" src="https://dirms4qsy6412.cloudfront.net/packs/js/ls_track-4ba11c63b23b3f4ff0d5.js">
  </script>
  <script defer="defer" src="https://dirms4qsy6412.cloudfront.net/packs/js/878-f45f15fbfda805bfd81c.js">
  </script>
  <script defer="defer" src="https://dirms4qsy6412.cloudfront.net/packs/js/highlight-6837aec390cb6f835178.js">
  </script>
 </body>
</html>
